{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digit classification with MLPs\n",
    "\n",
    "In this notebook, we'll train a multi-layer perceptron model to classify MNIST digits using **PyTorch**. \n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU, device name:', torch.cuda.get_device_name(0))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('No GPU found, using CPU instead.') \n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "PyTorch has two classes from [`torch.utils.data` to work with data](https://pytorch.org/docs/stable/data.html#module-torch.utils.data): \n",
    "- [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) which represents the actual data items, such as images or pieces of text, and their labels\n",
    "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) which is used for processing the dataset in batches in an efficient manner.\n",
    "\n",
    "PyTorch has domain-specific libraries with utilities for common data types such as [TorchText](https://pytorch.org/text/stable/index.html), [TorchVision](https://pytorch.org/vision/stable/index.html) and [TorchAudio](https://pytorch.org/audio/stable/index.html).\n",
    "\n",
    "Here we will use TorchVision and `torchvision.datasets` which provides easy access to [many common visual datasets](https://pytorch.org/vision/stable/datasets.html). In this example we'll use the [MNIST class](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) for loading the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "slurm_project = os.getenv('SLURM_JOB_ACCOUNT')\n",
    "data_dir = os.path.join('/scratch', slurm_project, 'data') if slurm_project else './data'\n",
    "print('data_dir =', data_dir)\n",
    "\n",
    "train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=ToTensor())\n",
    "test_dataset = datasets.MNIST(data_dir, train=False, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data loaders provide a way of iterating (making a loop over) the datasets, each time getting a new batch of data with the given batch size.\n",
    "\n",
    "The first element of the data batch (`data`) is a 4th-order tensor of size (`batch_size`, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels, where the first value is the number of color channels (only 1 in this case as it's gray scale).\n",
    "\n",
    "The second element of the batch (`target`) is a vector containing the correct (or \"target\") classes (\"0\", \"1\", ..., \"9\") for each training digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (data, target) in train_loader:\n",
    "    print('data:', data.size(), 'type:', data.type())\n",
    "    print('target:', target.size(), 'type:', target.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 10 training digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(data[i,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n",
    "    plt.title('Class: '+str(target[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron (MLP) network\n",
    "\n",
    "In PyTorch, a neural network is defined as a Python class. It needs to have two methods:\n",
    "\n",
    "- `__init__()` which initializes the layers used in the network\n",
    "- `forward()` which defines how the network performs a forward pass\n",
    "\n",
    "PyTorch will then automatically generate a `backward()` method that computes the gradients based on the computation done in the forward pass.\n",
    "\n",
    "All the [neural network building blocks defined in PyTorch can be found in the torch.nn documentation](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "We use `nn.Sequential` to more easily create a simple sequental neural network:\n",
    "\n",
    "- First we need to \"flatten\" the 2D image into a vector with `nn.Flatten`\n",
    "\n",
    "- Next a fully-connected layer with 20 neurons is created with `nn.Linear`. Note that we need to specify the number of input and output connections. In this case there are 28x28=784 inputs, and 20 outputs\n",
    "\n",
    "- Next, a ReLU non-linear activation\n",
    "\n",
    "- Finally the output of the last layer needs to be a 10-dimensional vector to match the ground truth of ten classes (the ten digits).\n",
    "\n",
    "The output of the last layer should be normalized with softmax, but this is actually included implicitly in the loss function in PyTorch (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 32\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        #dropout layer\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO: Implement Conv1 >> ReLU >> Conv2 >> ReLU >> MaxPool >> Dropout >> Flatten >> FC1 >> ReLU >> Dropout >> FC2 >> probability logits\n",
    "        \n",
    "        output = ???\n",
    "        return output\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "In order to train the model we need to define a loss function and an optimizer.\n",
    "\n",
    "For a classification task we typically use the cross entropy loss. For this we can use the class [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "\n",
    "**Note:** if you read the documentation of `CrossEntropyLoss` carefully you will see that it expects the unnormalized raw outputs of the model as softmax is included implicitly in PyTorch's implementation of `CrossEntropyLoss`. This is why we don't need to explicitly use softmax in the network definition above.\n",
    "\n",
    "Finally, we need to define an optimizer, which tells how to update the model parameters based on the computed gradients. There are [several different optimizer algorithms implemented in PyTorch](https://pytorch.org/docs/stable/optim.html#algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch we have to write the training loop ourselves.\n",
    "\n",
    "The code below consists of two loops:\n",
    "\n",
    "- The outer loop goes over a number of *epochs*. An epoch is a single pass through the whole training data.\n",
    "- The inner loop goes through the whole dataset, a batch at a time. Here we have defined the batch size to be 32, so images are handled 32 at a time.\n",
    "\n",
    "For each batch we:\n",
    "\n",
    "- Copy the data to the GPU with the `.to(device)` method. If we don't have a GPU, these commands will not do anything.\n",
    "\n",
    "- Do a forward pass, which is as simple as: `output = model(data)`\n",
    "\n",
    "- Finally we calculate the loss - that is the error between the output of the network and the target we want to get - using the `criterion` function we defined earlier\n",
    "\n",
    "- The last lines do the backward propagation with `loss.backward()`, the weights are updated with `optimizer.step()` and finally we need to zero the gradient counters with `optimizer.zero_grad()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a helper function to calculate the number of correctly classified digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(output, target):\n",
    "    predicted_digits = output.argmax(1)                            # pick digit with largest network output\n",
    "    correct_ones = (predicted_digits == target).type(torch.float)  # 1.0 for correct, 0.0 for incorrect\n",
    "    return correct_ones.sum().item()                               # count number of correct ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function for a single training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    num_items = len(data_loader.dataset)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for data, target in data_loader:\n",
    "        # Copy data and targets to GPU\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Do a forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Count number of correct digits\n",
    "        total_correct += correct(output, target)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    train_loss = total_loss/num_batches\n",
    "    accuracy = total_correct/num_items\n",
    "    print(f\"Average loss: {train_loss:7f}, accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Training epoch: {epoch+1}\")\n",
    "    train(train_loader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "For a better measure of the quality of the model, let's see the model accuracy for the test data.\n",
    "\n",
    "The code is similar to the training code: we just loop over the whole testset, but no need to do backpropagation or calculate any gradients this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(test_loader)\n",
    "    num_items = len(test_loader.dataset)\n",
    "\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Copy data and targets to GPU\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "        \n",
    "            # Do a forward pass\n",
    "            output = model(data)\n",
    "        \n",
    "            # Calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "        \n",
    "            # Count number of correct digits\n",
    "            total_correct += correct(output, target)\n",
    "\n",
    "    test_loss = test_loss/num_batches\n",
    "    accuracy = total_correct/num_items\n",
    "\n",
    "    print(f\"Testset accuracy: {100*accuracy:>0.1f}%, average loss: {test_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader, model, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
